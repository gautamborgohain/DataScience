{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to get details of the top 250 movies in IMDB from IMDB, Metacritic and Rotten tomatoes\n",
    "\n",
    "## by Gautam Borgohain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import urllib.request as req\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "headers={'User-Agent':user_agent,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Function to get the soup objects for a given URL\n",
    "#\n",
    "def getSoup(url):\n",
    "    request= req.Request(url,None,headers)\n",
    "    try:\n",
    "        response = req.urlopen(request) \n",
    "        time.sleep(2)\n",
    "        data = response.read()\n",
    "        soup = BeautifulSoup(data, \"html.parser\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"There was an error retrieving\", url, e) \n",
    "    finally:\n",
    "        response.close()\n",
    "        \n",
    "    return soup\n",
    "\n",
    "def cleanText(text):\n",
    "    return re.sub(r'\\n','',text)\n",
    "\n",
    "url_start = \"http://www.imdb.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Get the Top 250 Movie list from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb250_url = \"http://www.imdb.com/chart/top?ref_=nv_mv_250_6\"\n",
    "\n",
    "imdb250_soup = getSoup(imdb250_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Loop through the 250 movies and extract the movie name, rating and the url to their main page and store the data to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table250 = imdb250_soup.find('tbody',{'class': 'lister-list'})\n",
    "top250_df = pd.DataFrame(columns=['Title','Rating','IMDB_MAIN_URL'])# Initialize an empty dataframe\n",
    "for movie_row in table250.findAll('tr'):\n",
    "    title_cell = movie_row.find('td',{'class':'titleColumn'})\n",
    "    if(title_cell.a):\n",
    "        movie_url = url_start+ title_cell.a['href']\n",
    "        movie_name = title_cell.a.text\n",
    "    rating_cell = movie_row.find('td',{'class':'ratingColumn imdbRating'})\n",
    "    if(rating_cell):\n",
    "        rating = cleanText(rating_cell.text)\n",
    "    top250_df.loc[len(top250_df)] = [movie_name,rating,movie_url]\n",
    "    \n",
    "top250_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Loop through the dataframe and go to each movie's main page using the url obtained in the previous step.\n",
    "\n",
    "From the main page, get Year and Genre information of the movies along with the link to the movie's awards page. Finally add everything into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top250_df_copy = top250_df.copy()\n",
    "# top250_df_copy = top250_df_copy[0:100]\n",
    "\n",
    "year_list = []\n",
    "all_genre_list = []\n",
    "awards_url_list = []\n",
    "for index, row in top250_df_copy.iterrows():\n",
    "    temp_url = row['IMDB_MAIN_URL']\n",
    "    oneMovie = getSoup(temp_url)\n",
    "    year_soup = oneMovie.find('span',{'id':'titleYear'})\n",
    "    year = re.sub(r'[()]',\"\",year_soup.text)\n",
    "    genre_soup = oneMovie.findAll('span',{'itemprop':'genre'})\n",
    "    genre_list = []\n",
    "    for genre in genre_soup:\n",
    "        genre_list.append(genre.text)\n",
    "    awards_soup = oneMovie.find(text = 'See more awards')\n",
    "    if(awards_soup):\n",
    "        moreawards_url = url_start + awards_soup.parent['href']\n",
    "    year_list.append(year)\n",
    "    all_genre_list.append(' '.join(genre_list)) # Using a lit here. Maybe put them in different columns? Dont know if that would be useful\n",
    "    awards_url_list.append(moreawards_url)\n",
    "    moreawards_url = \" \"# Cleaning the variable in case the next movie does not have an awards page\n",
    "    time.sleep(2)\n",
    "    if(index%25==0):print(\"Fetched till \",index)\n",
    "\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns), column = 'YEAR',value = year_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='Genre',value =all_genre_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='IMDB_AWARDS_URL',value = awards_url_list)\n",
    "\n",
    "top250_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Go to each of the awards page in the dataframe and extract the number of awards won by the movie.\n",
    "\n",
    "The awards that are of interest to use are:\n",
    "- Oscars - Academy awards\n",
    "- BAFTA\n",
    "- SAG\n",
    "- Golden globes\n",
    "- Critics Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oscar_nominations_list = []\n",
    "oscar_wins_list = []\n",
    "gg_nominations_list = []\n",
    "gg_wins_list = []\n",
    "sag_nominations_list = []\n",
    "sag_wins_list = []\n",
    "bafta_nominations_list = []\n",
    "bafta_wins_list = []\n",
    "cc_wins_list = []\n",
    "cc_nominations_list = []\n",
    "total_nominations_list = []\n",
    "total_wins_list = []\n",
    "\n",
    "def getCount(td):\n",
    "    return td.get('rowspan') if (td.get('rowspan')) else 0\n",
    "\n",
    "def toNumber(numberlist):\n",
    "    return numberlist[0] if(numberlist) else 0\n",
    "\n",
    "for index, row in top250_df_copy.iterrows():\n",
    "    temp_url = row['IMDB_AWARDS_URL']\n",
    "    if(temp_url != ' '): \n",
    "        temp_soup = getSoup(temp_url)\n",
    "        allstats = temp_soup.find('div',{'class':'desc'})\n",
    "        total_wins = toNumber(re.findall(r'([0-9]*) wins',allstats.text))\n",
    "        total_nominations = toNumber(re.findall(r'([0-9]*) nominations',allstats.text))\n",
    "        td_award = temp_soup.findAll('td', {'class': 'title_award_outcome'})\n",
    "        oscar_win=0\n",
    "        oscar_nom=0\n",
    "        BAFTA_win=0\n",
    "        BAFTA_nom=0\n",
    "        gg_win=0\n",
    "        gg_nom=0\n",
    "        sag_win=0\n",
    "        sag_nom=0\n",
    "        cc_win=0\n",
    "        cc_nom =0\n",
    "        for td in td_award:\n",
    "            if 'Won\\nOscar' in td.text:\n",
    "                oscar_win = getCount(td)\n",
    "            elif 'Nominated\\nOscar' in td.text:\n",
    "                oscar_nom = getCount(td)\n",
    "            elif 'Won\\nBAFTA' in td.text:\n",
    "                BAFTA_win = getCount(td)\n",
    "            elif 'Nominated\\nBAFTA' in td.text:\n",
    "                BAFTA_nom = getCount(td)       \n",
    "            elif 'Won\\nGolden Globe' in td.text:\n",
    "                gg_win = getCount(td)        \n",
    "            elif 'Nominated\\nGolden Globe' in td.text:\n",
    "                gg_nom = getCount(td)        \n",
    "            elif 'Won\\nActor' in td.text:\n",
    "                sag_win = getCount(td)        \n",
    "            elif 'Nominated\\nActor' in td.text:\n",
    "                sag_nom = getCount(td)        \n",
    "            elif 'Won\\nCritics Choice' in td.text:\n",
    "                cc_win = getCount(td)    \n",
    "            elif 'Nominated\\nCritics Choice' in td.text:\n",
    "                cc_nom = getCount(td)\n",
    "        oscar_wins_list.append(oscar_win)\n",
    "        oscar_nominations_list.append(oscar_nom)\n",
    "        cc_wins_list.append(cc_win )\n",
    "        cc_nominations_list.append(cc_nom )\n",
    "        bafta_wins_list.append(BAFTA_win)\n",
    "        bafta_nominations_list.append(BAFTA_nom)\n",
    "        gg_wins_list.append(gg_win)\n",
    "        gg_nominations_list.append(gg_nom)\n",
    "        sag_wins_list.append(sag_win)\n",
    "        sag_nominations_list.append(sag_nom)\n",
    "        total_nominations_list.append(total_nominations)\n",
    "        total_wins_list.append(total_wins)\n",
    "        if(index%25==0):\n",
    "            print(\"Fetched till \",index)\n",
    "\n",
    "movies_withoutAwards = top250_df_copy.loc[top250_df_copy.IMDB_AWARDS_URL == ' ']            \n",
    "top250_df_copy = top250_df_copy.loc[top250_df_copy.IMDB_AWARDS_URL != ' ']# Remove the movies that did not have awards page\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='TOTAL_NOM',value = total_nominations_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='TOTAL_WINS',value = total_wins_list)   \n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns), column = 'OSCAR_NOM',value = oscar_nominations_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='OSCAR_WIN',value =oscar_wins_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='GG_NOM',value = gg_nominations_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='GG_WINS',value = gg_wins_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns), column = 'BAFTA_NOM',value = bafta_nominations_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='BAFTA_WIN',value =bafta_wins_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='SAG_NOM',value = sag_nominations_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='SAG_WINS',value = sag_wins_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='CC_NOM',value = cc_nominations_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='CC_WINS',value = cc_wins_list)\n",
    "# top250_df_copy = top250_df_copy.append(movies_withoutAwards)# To append the movies without the awards\n",
    "top250_df_copy.head()\n",
    "\n",
    "\n",
    "# top250_df_copy['TOTAL_NOM'] = [toNumber(i) for i in top250_df_copy['TOTAL_NOM']]\n",
    "# top250_df_copy['TOTAL_WINS'] = [toNumber(i) for i in top250_df_copy['TOTAL_WINS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metacritic\n",
    "\n",
    "Step 5: Go over all the movies in the data frame, go to Metacritic.com and extract the critic and user ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metaSearch_Start_url = 'http://www.metacritic.com/search/movie/'\n",
    "metaSearch_End_url = \"/results\"\n",
    "meta_home = \"http://www.metacritic.com/\"\n",
    "critic_score_list = []\n",
    "user_score_list = []\n",
    "movie_url_list = []\n",
    "for index, row in top250_df_copy.iterrows():\n",
    "    critic_score = 0\n",
    "    user_score = 0\n",
    "    movie_name = row['Title']\n",
    "    movie_name_encoded = quote(movie_name.encode('utf8'))\n",
    "    metaSearch_url = metaSearch_Start_url+movie_name_encoded+metaSearch_End_url\n",
    "    results_soup = getSoup(metaSearch_url)\n",
    "    time.sleep(2)\n",
    "    firstResult = results_soup.find(text = movie_name) # Search the results for the exact movie name\n",
    "    if(firstResult):\n",
    "        movie_home_url_part = firstResult.parent['href']\n",
    "        movie_home_url = meta_home+movie_home_url_part\n",
    "        movie_soup = getSoup(movie_home_url) # Go to the movie's metacritic homepage\n",
    "        critic_shell = movie_soup.findAll('a',{'class':'metascore_anchor'}) # This gives a list of all the scores, we need the first two\n",
    "        if(critic_shell):\n",
    "            critic_score = cleanText(critic_shell[0].text)\n",
    "            user_score = cleanText(critic_shell[1].text)\n",
    "    movie_url_list.append(metaSearch_url)\n",
    "    critic_score_list.append(critic_score)\n",
    "    user_score_list.append(user_score)\n",
    "    time.sleep(2)\n",
    "    if(index%25==0):print(\"Fetched till \",index)\n",
    "\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_MOVIE_URL',value = movie_url_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_CRITIC_RATING',value = critic_score_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_USER_RATING',value = user_score_list)\n",
    "top250_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotten Tomatoes\n",
    "\n",
    "Step 6: Iterate through the list of movies and go to Rottentomatoes.com to get the User and critic ratings.\n",
    "\n",
    "Problem here is that the web site behaves differently for some movies.For some movies, even sending a request via 'search' url, the user is taken directly to the home pagep of the movie. Thus have to create condition to make sure we are in the right page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rotten_home = \"http://www.rottentomatoes.com\"\n",
    "rotten_search_start = \"http://www.rottentomatoes.com/search/?search=\"\n",
    "critic_score_list = []\n",
    "user_score_list = []\n",
    "movie_url_list = []\n",
    "\n",
    "def getMovieURL(movie_name,results_soup):\n",
    "    ul = results_soup.find('ul',{'id': 'movie_results_ul'})\n",
    "    if(ul):\n",
    "        lis = ul.findAll('li',{'class':'media bottom_divider clearfix'})\n",
    "        for li in lis:\n",
    "            if movie_name.lower() in li.text.lower().encode('ascii','ignore').decode('utf8'):\n",
    "                return li.find('a')['href']\n",
    "    return False\n",
    "\n",
    "for index, row in top250_df_copy.iterrows():\n",
    "    critic_score = 0\n",
    "    user_score = 0\n",
    "    movie_name = row['Title'].encode('ascii','ignore').decode('utf8')\n",
    "    movie_name_encoded = re.sub(' ','+',movie_name)\n",
    "    rtSearch_url = rotten_search_start+movie_name_encoded\n",
    "    results_soup = getSoup(rtSearch_url)\n",
    "    time.sleep(2)\n",
    "    if(results_soup):\n",
    "        resultsdiv = results_soup.findAll('div',{'id':'scoreStats'})\n",
    "        if(resultsdiv): # If it went to the Home Page directly\n",
    "#             print(\"Hom page\", movie_name)\n",
    "            text = resultsdiv[0].text\n",
    "            critic_rating = toNumber(re.findall(r'Average Rating:  ([^/]+)',text))\n",
    "            resultsdiv = results_soup.findAll('div',{'class':'audience-info hidden-xs superPageFontColor'})\n",
    "            text = resultsdiv[0].text\n",
    "            user_rating = toNumber(re.findall(r'Average Rating: ([^/]+)',text))\n",
    "            critic_score_list.append(critic_rating)\n",
    "            user_score_list.append(user_rating)\n",
    "            movie_url_list.append(rtSearch_url)\n",
    "        else:\n",
    "#             print(\"Went to search page\", movie_name,rtSearch_url)\n",
    "            home_url = getMovieURL(movie_name,results_soup)\n",
    "            if(home_url):\n",
    "                complete_home_url = rotten_home+home_url\n",
    "                results_list= getSoup(complete_home_url)\n",
    "                resultsdiv = results_list.findAll('div',{'id':'scoreStats'})\n",
    "                if(len(resultsdiv)>0):\n",
    "#                     print(\"Now to Home page\", movie_name)\n",
    "                    text = resultsdiv[0].text\n",
    "                    critic_rating = toNumber(re.findall(r'Average Rating:  ([^/]+)',text))\n",
    "                    resultsdiv = results_list.findAll('div',{'class':'audience-info hidden-xs superPageFontColor'})\n",
    "                    text = resultsdiv[0].text\n",
    "                    user_rating = toNumber(re.findall(r'Average Rating: ([^/]+)',text))\n",
    "                    critic_score_list.append(critic_rating)\n",
    "                    user_score_list.append(user_rating)\n",
    "                    movie_url_list.append(complete_home_url)\n",
    "                else:\n",
    "                    print(\"Didnt find ratings info\", resultsdiv,complete_home_url)\n",
    "                    critic_score_list.append(0)\n",
    "                    user_score_list.append(0)\n",
    "                    movie_url_list.append(complete_home_url)\n",
    "            else:\n",
    "                print(\"Movie not in the result list\", home_url,rtSearch_url)\n",
    "                critic_score_list.append(0)\n",
    "                user_score_list.append(0)\n",
    "                movie_url_list.append(rtSearch_url)\n",
    "                \n",
    "    time.sleep(2)\n",
    "    if(index%25==0):print(\"Fetched till \",index)\n",
    "\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='RT_MOVIE_URL',value = movie_url_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='RT_CRITIC_RATING',value = critic_score_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='RT_USER_RATING',value = user_score_list)\n",
    "top250_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and some calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top250_df_copy.loc[top250_df_copy.RT_CRITIC_RATING == 'N'] = 0\n",
    "top250_df_copy.loc[top250_df_copy.RT_USER_RATING == 'N'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the columns to float datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in top250_df_copy.columns:\n",
    "    if column not in ['Genre','IMDB_AWARDS_URL','IMDB_MAIN_URL','Title','RT_MOVIE_URL','MC_MOVIE_URL','YEAR']:\n",
    "        top250_df_copy[[column]] = top250_df_copy[[column]].astype(float, inplace  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top250_df_copy['AVG_USR_RATING'] = (top250_df_copy.Rating + (2 * top250_df_copy.RT_USER_RATING) + top250_df_copy.MC_USER_RATING) / 3\n",
    "top250_df_copy['AVG_CRTC_RATING'] = (top250_df_copy.RT_CRITIC_RATING + (top250_df_copy.MC_CRITIC_RATING / 10)) / 2\n",
    "top250_df_copy['TOTAL_AWARDS'] = (3 * top250_df_copy.TOTAL_WINS + top250_df_copy.TOTAL_NOM) + (3 * (\n",
    "top250_df_copy.OSCAR_WIN + top250_df_copy.SAG_WINS + top250_df_copy.BAFTA_WIN + top250_df_copy.CC_WINS + top250_df_copy.GG_WINS)) + (\n",
    "                                 top250_df_copy.BAFTA_NOM + top250_df_copy.GG_NOM + top250_df_copy.CC_NOM + top250_df_copy.OSCAR_NOM + top250_df_copy.SAG_NOM)\n",
    "\n",
    "top250_df_copy['AVG_RATING'] = (top250_df_copy.AVG_USR_RATING+top250_df_copy.AVG_CRTC_RATING) / 2\n",
    "top250_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top250_df_copy = pd.read_csv('/Users/gautamborgohain/Desktop/temp5.csv')\n",
    "top250_df_copy_backup = top250_df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top250_df_copy.to_csv('/Users/gautamborgohain/Desktop/step1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the 1000 movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top1000_df = pd.DataFrame(columns=['Title','Rating','IMDB_MAIN_URL'])# Initialize an empty dataframe\n",
    "list_home_url = 'http://www.imdb.com/search/title?groups=top_1000&sort=user_rating&start=@@@&view=simple'\n",
    "for i in range(1,1000,100):\n",
    "    pagesoup = getSoup(re.sub('@@@',str(i),list_home_url))\n",
    "    rows = pagesoup.findAll('tr',{'class':re.compile('even|odd')})\n",
    "    for row in rows:\n",
    "        try:\n",
    "            movie_name = row.find('a').text\n",
    "            movie_url = url_start+row.find('a')['href']\n",
    "            rating = row.find('b').text\n",
    "            top1000_df.loc[len(top1000_df)] = [movie_name,rating,movie_url]\n",
    "        except Exception as e:\n",
    "            print(row.text, movie_url,e)\n",
    "top1000_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top1000_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top250_df = top1000_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top1000_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top250_df_copy = top250_df\n",
    "len(top250_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed getting awards 'IMDB_AWARDS_URL'\n",
      "Fetched till  0\n",
      "Fetched till  25\n",
      "Fetched till  50\n",
      "Fetched till  75\n",
      "Fetched till  100\n",
      "Fetched till  125\n",
      "Fetched till  150\n",
      "Fetched till  175\n",
      "Fetched till  200\n",
      "Fetched till  225\n",
      "Fetched till  250\n",
      "Fetched till  275\n",
      "Fetched till  300\n",
      "Fetched till  325\n",
      "Fetched till  350\n",
      "Fetched till  375\n",
      "Fetched till  400\n",
      "Fetched till  425\n",
      "Fetched till  450\n",
      "Fetched till  475\n",
      "Fetched till  500\n",
      "Fetched till  525\n",
      "Fetched till  550\n",
      "Fetched till  575\n",
      "Fetched till  600\n",
      "Fetched till  625\n",
      "Fetched till  650\n",
      "There was an error retrieving http://www.metacritic.com/search/movie/Frost/Nixon/results HTTP Error 404: Not Found\n",
      "Failed getting Metacritic local variable 'soup' referenced before assignment\n",
      "Fetched till  0\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/seven_samurai/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/city_of_god_2011/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/life_is_beautiful_2012/\n",
      "Fetched till  25\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Lon:+The+Professional\n",
      "Fetched till  50\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=3+Idiots\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=WALLE\n",
      "Fetched till  75\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/bicycle_thieves_2013/\n",
      "Fetched till  100\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Snatch.\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Swades:+We,+the+People\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_huntsman_winters_war/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Dilwale+Dulhania+Le+Jayenge\n",
      "Fetched till  125\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/downfall_2011/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/ranbanka/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/on_the_waterfront_presented_by_tcm/\n",
      "Fetched till  150\n",
      "Fetched till  175\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/spindrift_a_tribute_to_rush/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_maltese_falcon_75th_anniversary_presented_by_tcm/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=The+Legend+of+1900\n",
      "Fetched till  200\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Kill+Bill:+Vol.+1\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/butch_cassidy_and_the_sundance_kid_presented_by_tcm/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/dokument-fanny-och-alexander/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/ben_hur_2016/\n",
      "Fetched till  225\n",
      "Fetched till  250\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Spring,+Summer,+Fall,+Winter...+and+Spring\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/tcm_presents_roman_holiday/\n",
      "Fetched till  275\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=The+Killing\n",
      "Fetched till  300\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Pink+Floyd+The+Wall\n",
      "Fetched till  325\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/jab_we_met/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/star_trek_beyond/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/nosferatu_2012/\n",
      "Fetched till  350\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/ghost_in_the_shell_the_new_movie/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Secrets+&+Lies\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Kill+Bill:+Vol.+2\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_iron_giant_signature_edition/\n",
      "Fetched till  375\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Gegen+die+Wand\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/planet_of_the_apes_presented_by_tcm/\n",
      "Fetched till  400\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/bolshoi_ballet_spartacus/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_hobbit_an_unexpected_journey_extended_edition_2015/\n",
      "Fetched till  425\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_hobbit_the_desolation_of_smaug_extended_edition/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/gora/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/ghayal_once_again/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the-chaser/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Jubei+the+Wind+Ninja\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/liberating_a_continent_john_paul_ii_and_the_fall_of_communism/\n",
      "Fetched till  450\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Lilya+4-ever\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/tcm_presents_miracle_on_34th_street/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_pastor_event/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_ten_commandments_presented_by_tcm/\n",
      "Fetched till  475\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/ferris_buellers_day_off_presented_by_tcm/\n",
      "Fetched till  500\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Pafekuto+buru\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/771422158/\n",
      "Fetched till  525\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/hamlet_2016/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Evil+Dead+II\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/open_your_eyes/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Willy+Wonka+&+the+Chocolate+Factory\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/fantasia_75th_anniversary/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_magnificent_seven_2016/\n",
      "Fetched till  550\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Pride+&+Prejudice\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/ghostbusters_2016/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Birdman+or+(The+Unexpected+Virtue+of+Ignorance)\n",
      "Fetched till  575\n",
      "Fetched till  600\n",
      "Fetched till  625\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Papurika\n",
      "Fetched till  650\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Adaptation.\n",
      "Fetched till  675\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_iron_giant_signature_edition/\n",
      "Fetched till  700\n",
      "Fetched till  725\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Fucking+ml\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Y+Tu+Mam+Tambin\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=La+mme\n",
      "Fetched till  750\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/mash-sf/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/kiss-kiss-bang-bang-2000/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_jungle_book_2016/\n",
      "Fetched till  775\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=The+Godfather:+Part+III\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_raid_1954/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Innocence:+Ghost+in+the+Shell\n",
      "Fetched till  800\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/tcm_presents_national_lampoons_animal_house/\n",
      "Fetched till  825\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Mesrine+Part+1:+Killer+Instinct\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Interview+with+the+Vampire:+The+Vampire+Chronicles\n",
      "Fetched till  850\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/ice_age_collision_course/\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/rain_in_the_town/\n",
      "Fetched till  875\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Planes,+Trains+&+Automobiles\n",
      "Fetched till  900\n",
      "Fetched till  925\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/the_conjuring_2/\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=Malna\n",
      "Fetched till  950\n",
      "Movie not in the result list False http://www.rottentomatoes.com/search/?search=The+Texas+Chain+Saw+Massacre\n",
      "Fetched till  975\n",
      "Didnt find ratings info [] http://www.rottentomatoes.com/m/alice_in_wonderland_through_the_looking_glass/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    oscar_nominations_list = []\n",
    "    oscar_wins_list = []\n",
    "    gg_nominations_list = []\n",
    "    gg_wins_list = []\n",
    "    sag_nominations_list = []\n",
    "    sag_wins_list = []\n",
    "    bafta_nominations_list = []\n",
    "    bafta_wins_list = []\n",
    "    cc_wins_list = []\n",
    "    cc_nominations_list = []\n",
    "    total_nominations_list = []\n",
    "    total_wins_list = []\n",
    "\n",
    "    def getCount(td):\n",
    "        return td.get('rowspan') if (td.get('rowspan')) else 0\n",
    "\n",
    "    def toNumber(numberlist):\n",
    "        return numberlist[0] if(numberlist) else 0\n",
    "\n",
    "    for index, row in top250_df_copy.iterrows():\n",
    "        temp_url = row['IMDB_AWARDS_URL']\n",
    "        if(temp_url != ' '): \n",
    "            temp_soup = getSoup(temp_url)\n",
    "            allstats = temp_soup.find('div',{'class':'desc'})\n",
    "            total_wins = toNumber(re.findall(r'([0-9]*) wins',allstats.text))\n",
    "            total_nominations = toNumber(re.findall(r'([0-9]*) nominations',allstats.text))\n",
    "            td_award = temp_soup.findAll('td', {'class': 'title_award_outcome'})\n",
    "            oscar_win=0\n",
    "            oscar_nom=0\n",
    "            BAFTA_win=0\n",
    "            BAFTA_nom=0\n",
    "            gg_win=0\n",
    "            gg_nom=0\n",
    "            sag_win=0\n",
    "            sag_nom=0\n",
    "            cc_win=0\n",
    "            cc_nom =0\n",
    "            for td in td_award:\n",
    "                if 'Won\\nOscar' in td.text:\n",
    "                    oscar_win = getCount(td)\n",
    "                elif 'Nominated\\nOscar' in td.text:\n",
    "                    oscar_nom = getCount(td)\n",
    "                elif 'Won\\nBAFTA' in td.text:\n",
    "                    BAFTA_win = getCount(td)\n",
    "                elif 'Nominated\\nBAFTA' in td.text:\n",
    "                    BAFTA_nom = getCount(td)       \n",
    "                elif 'Won\\nGolden Globe' in td.text:\n",
    "                    gg_win = getCount(td)        \n",
    "                elif 'Nominated\\nGolden Globe' in td.text:\n",
    "                    gg_nom = getCount(td)        \n",
    "                elif 'Won\\nActor' in td.text:\n",
    "                    sag_win = getCount(td)        \n",
    "                elif 'Nominated\\nActor' in td.text:\n",
    "                    sag_nom = getCount(td)        \n",
    "                elif 'Won\\nCritics Choice' in td.text:\n",
    "                    cc_win = getCount(td)    \n",
    "                elif 'Nominated\\nCritics Choice' in td.text:\n",
    "                    cc_nom = getCount(td)\n",
    "            oscar_wins_list.append(oscar_win)\n",
    "            oscar_nominations_list.append(oscar_nom)\n",
    "            cc_wins_list.append(cc_win )\n",
    "            cc_nominations_list.append(cc_nom )\n",
    "            bafta_wins_list.append(BAFTA_win)\n",
    "            bafta_nominations_list.append(BAFTA_nom)\n",
    "            gg_wins_list.append(gg_win)\n",
    "            gg_nominations_list.append(gg_nom)\n",
    "            sag_wins_list.append(sag_win)\n",
    "            sag_nominations_list.append(sag_nom)\n",
    "            total_nominations_list.append(total_nominations)\n",
    "            total_wins_list.append(total_wins)\n",
    "            if(index%25==0):\n",
    "                print(\"Fetched till \",index)\n",
    "\n",
    "    movies_withoutAwards = top250_df_copy.loc[top250_df_copy.IMDB_AWARDS_URL == ' ']            \n",
    "    top250_df_copy = top250_df_copy.loc[top250_df_copy.IMDB_AWARDS_URL != ' ']# Remove the movies that did not have awards page\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='TOTAL_NOM',value = total_nominations_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='TOTAL_WINS',value = total_wins_list)   \n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns), column = 'OSCAR_NOM',value = oscar_nominations_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='OSCAR_WIN',value =oscar_wins_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='GG_NOM',value = gg_nominations_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='GG_WINS',value = gg_wins_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns), column = 'BAFTA_NOM',value = bafta_nominations_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='BAFTA_WIN',value =bafta_wins_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='SAG_NOM',value = sag_nominations_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='SAG_WINS',value = sag_wins_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='CC_NOM',value = cc_nominations_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='CC_WINS',value = cc_wins_list)\n",
    "\n",
    "    top250_df_copy.to_csv('/Users/gautamborgohain/Desktop/step2_awards.csv')\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Failed getting awards\", e)\n",
    "    \n",
    "try:    \n",
    "    metaSearch_Start_url = 'http://www.metacritic.com/search/movie/'\n",
    "    metaSearch_End_url = \"/results\"\n",
    "    meta_home = \"http://www.metacritic.com/\"\n",
    "    critic_score_list = []\n",
    "    user_score_list = []\n",
    "    movie_url_list = []\n",
    "    for index, row in top250_df_copy.iterrows():\n",
    "        critic_score = 0\n",
    "        user_score = 0\n",
    "        movie_name = row['Title']\n",
    "        movie_name_encoded = quote(movie_name.encode('utf8'))\n",
    "        metaSearch_url = metaSearch_Start_url+movie_name_encoded+metaSearch_End_url\n",
    "        results_soup = getSoup(metaSearch_url)\n",
    "        time.sleep(1)\n",
    "        firstResult = results_soup.find(text = movie_name) # Search the results for the exact movie name\n",
    "        if(firstResult):\n",
    "            movie_home_url_part = firstResult.parent['href']\n",
    "            movie_home_url = meta_home+movie_home_url_part\n",
    "            movie_soup = getSoup(movie_home_url) # Go to the movie's metacritic homepage\n",
    "            critic_shell = movie_soup.findAll('a',{'class':'metascore_anchor'}) # This gives a list of all the scores, we need the first two\n",
    "            if(critic_shell):\n",
    "                critic_score = cleanText(critic_shell[0].text)\n",
    "                user_score = cleanText(critic_shell[1].text)\n",
    "        movie_url_list.append(metaSearch_url)\n",
    "        critic_score_list.append(critic_score)\n",
    "        user_score_list.append(user_score)\n",
    "        time.sleep(1)\n",
    "        if(index%25==0):print(\"Fetched till \",index)\n",
    "\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_MOVIE_URL',value = movie_url_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_CRITIC_RATING',value = critic_score_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_USER_RATING',value = user_score_list)\n",
    "\n",
    "    top250_df_copy.to_csv('/Users/gautamborgohain/Desktop/step3_meta.csv')\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Failed getting Metacritic\", e)\n",
    "\n",
    "try:\n",
    "    rotten_home = \"http://www.rottentomatoes.com\"\n",
    "    rotten_search_start = \"http://www.rottentomatoes.com/search/?search=\"\n",
    "    critic_score_list = []\n",
    "    user_score_list = []\n",
    "    movie_url_list = []\n",
    "\n",
    "    def getMovieURL(movie_name,results_soup):\n",
    "        ul = results_soup.find('ul',{'id': 'movie_results_ul'})\n",
    "        if(ul):\n",
    "            lis = ul.findAll('li',{'class':'media bottom_divider clearfix'})\n",
    "            for li in lis:\n",
    "                if movie_name.lower() in li.text.lower().encode('ascii','ignore').decode('utf8'):\n",
    "                    return li.find('a')['href']\n",
    "        return False\n",
    "\n",
    "    for index, row in top250_df_copy.iterrows():\n",
    "        critic_score = 0\n",
    "        user_score = 0\n",
    "        movie_name = row['Title'].encode('ascii','ignore').decode('utf8')\n",
    "        movie_name_encoded = re.sub(' ','+',movie_name)\n",
    "        rtSearch_url = rotten_search_start+movie_name_encoded\n",
    "        results_soup = getSoup(rtSearch_url)\n",
    "        time.sleep(1)\n",
    "        if(results_soup):\n",
    "            resultsdiv = results_soup.findAll('div',{'id':'scoreStats'})\n",
    "            if(resultsdiv): # If it went to the Home Page directly\n",
    "    #             print(\"Hom page\", movie_name)\n",
    "                text = resultsdiv[0].text\n",
    "                critic_rating = toNumber(re.findall(r'Average Rating:  ([^/]+)',text))\n",
    "                resultsdiv = results_soup.findAll('div',{'class':'audience-info hidden-xs superPageFontColor'})\n",
    "                text = resultsdiv[0].text\n",
    "                user_rating = toNumber(re.findall(r'Average Rating: ([^/]+)',text))\n",
    "                critic_score_list.append(critic_rating)\n",
    "                user_score_list.append(user_rating)\n",
    "                movie_url_list.append(rtSearch_url)\n",
    "            else:\n",
    "    #             print(\"Went to search page\", movie_name,rtSearch_url)\n",
    "                home_url = getMovieURL(movie_name,results_soup)\n",
    "                if(home_url):\n",
    "                    complete_home_url = rotten_home+home_url\n",
    "                    results_list= getSoup(complete_home_url)\n",
    "                    resultsdiv = results_list.findAll('div',{'id':'scoreStats'})\n",
    "                    if(len(resultsdiv)>0):\n",
    "    #                     print(\"Now to Home page\", movie_name)\n",
    "                        text = resultsdiv[0].text\n",
    "                        critic_rating = toNumber(re.findall(r'Average Rating:  ([^/]+)',text))\n",
    "                        resultsdiv = results_list.findAll('div',{'class':'audience-info hidden-xs superPageFontColor'})\n",
    "                        text = resultsdiv[0].text\n",
    "                        user_rating = toNumber(re.findall(r'Average Rating: ([^/]+)',text))\n",
    "                        critic_score_list.append(critic_rating)\n",
    "                        user_score_list.append(user_rating)\n",
    "                        movie_url_list.append(complete_home_url)\n",
    "                    else:\n",
    "                        print(\"Didnt find ratings info\", resultsdiv,complete_home_url)\n",
    "                        critic_score_list.append(0)\n",
    "                        user_score_list.append(0)\n",
    "                        movie_url_list.append(complete_home_url)\n",
    "                else:\n",
    "                    print(\"Movie not in the result list\", home_url,rtSearch_url)\n",
    "                    critic_score_list.append(0)\n",
    "                    user_score_list.append(0)\n",
    "                    movie_url_list.append(rtSearch_url)\n",
    "\n",
    "        time.sleep(1)\n",
    "        if(index%25==0):print(\"Fetched till \",index)\n",
    "\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='RT_MOVIE_URL',value = movie_url_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='RT_CRITIC_RATING',value = critic_score_list)\n",
    "    top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='RT_USER_RATING',value = user_score_list)\n",
    "\n",
    "    top250_df_copy.to_csv('/Users/gautamborgohain/Desktop/step4_rt.csv')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Failed getting rottentomatoes\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_MOVIE_URL',value = movie_url_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_CRITIC_RATING',value = critic_score_list)\n",
    "top250_df_copy.insert(loc = len(top250_df_copy.columns),column ='MC_USER_RATING',value = user_score_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top250_df_copy.to_csv('/Users/gautamborgohain/Desktop/step3_meta.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
